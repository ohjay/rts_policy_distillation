# -------------------------------------
# RTS Policy Distillation - Config File
# -------------------------------------

# RUN INFO
# --------

env: generals_sim
operation: train  # choices: (train,)

train_params:
  random_seed: 1
  num_timesteps: 40000000
  lr_multiplier: 1.0
  replay_buffer_size: 1000000
  batch_size: 64
  gamma: 0.99
  learning_starts: 50000
  learning_freq: 1
  frame_history_len: 1
  target_update_freq: 10000
  grad_norm_clipping: 10
  lr_schedule:  # can use any variables defined in `main.train`
    - 0: 1e-4 * lr_multiplier
    - num_iterations / 10: 1e-4 * lr_multiplier
    - num_iterations / 2: 5e-5 * lr_multiplier
  exploration_schedule:
    - 0: 0.80
    - 1e6: 0.10
    - num_iterations / 2: 0.01
  normalize_inputs: False
  log_freq: 50  # log every X episodes
  log_recent_rewards: True
  save_model: False
  save_images: False
  restore_from:  # TODO (currently not used)
    run_dir: run_11-30__20_35
    checkpoint: 50000

# ENV-SPECIFIC INFO
# ------------------
generals_sim:
  map_height: 18
  map_width: 18
  map_player_count: 2
  reward_fn_name: x_squares_acquired  # choice of reward function in `simulator.py`

reset_kwargs:
  map_init: empty  # choices: (empty, random)
  player_id: 1
  preprocessors:  # choice of preprocessors from `generals_sim.py`
    - add_dimension

step_kwargs:
  player_id: 1
  preprocessors:
    - add_dimension

get_action_kwargs:
  ensure_valid: True  # ensure that Q values produce a VALID action?

get_random_kwargs:
  semi_valid: True  # choose a random action that is guaranteed to "probably" be valid?
  player_id: 1

# MODEL ARCHITECTURE
# ------------------

dqn_arch:
  inputs:
    friendly:
      dtype: uint8
      shape: [18, 18, 1]

  layers:
    - inputs: [friendly]
      type: conv2d
      num_outputs: 32
      kernel_size: 8
      stride: 4
      activation: relu
    - type: conv2d
      num_outputs: 64
      kernel_size: 4
      stride: 2
      activation: relu
    - type: conv2d
      num_outputs: 64
      kernel_size: 3
      stride: 1
      activation: relu
    - type: fc
      num_outputs: 128
      activation: relu

  outputs:
#    action:
#      dtype: int32
#      shape: [1296]  # 18 * 18 * 4
#      activation: X

#    target_x:
#      dtype: int32
#      shape: [18]
#      activation: X
#      order: 0
#    target_y:
#      dtype: int32
#      shape: [18]
#      activation: X
#      order: 1
#    direction:
#      dtype: int32
#      shape: [4]  # five actions centered around active square
#      activation: X
#      order: 2

    target_xy:
      dtype: int32
      shape: [324]
      activation: X
      order: 0
    direction:
      dtype: int32
      shape: [4]  # five actions centered around active square
      activation: X
      order: 1
